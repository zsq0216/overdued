# Lab1_t3文档
## f(n,k)理论推导
* 已知Merge Sort的时间复杂度为Θ(nlgn),Insertion Sort的时间复杂度为Θ(n²)。为方便测试，不妨令
  **Merge T(n)=T(n/2) + c1 * n, Insertion T(n)=c2 * n²**
  
  其中c1,c2为常数，和机器有关。
  > *Introduction to Algorithms(3rd),39*
* Recursion-tree
  ![avatar](1.1.jpg)
  * 从数学角度分析，要选取固定的k使得f(n)尽可能小，则需要对k求偏导，由于f(k)的变化趋势是先减后增的，所以在偏导数等于0处的k值即为所求。
  ![avatar](1.4.jpg)
* 运行本地insertion.cpp、merge.cpp程序，通过测得排序运行时间，粗略计算c1、c2取值
  * 操作系统:Windows 10
  * 处理器:AMD Ryzen 7 4800H with Radeon Graphics 2.90 GHz
  * IDE:VScode
  * 程序运行前本机状态:4%CPU,43%内存,4%磁盘,0%网络
![avatar](1.2.jpg)
  * 可知c1的数量级约为E-08,c2的数量级约为E-09
  * **k的理论值为47(c1/c2取平均值)或37(c1/c2取线性拟合结果)**
## selectK()设计思路
* 经过粗略实验发现k大于200时排序的运行速度几乎不会比小于100的来得快，测出的数据对实验没什么意义。为了给机器减负，但同时不能太消极怠工，于是限定k的范围为[1,500]。
* 让combineSort依次取k=1,2,3……500,对相同长度为10000的整型序列做500次排序。注意到排序算法会改变数组序列，所以每次排序前都要另外开辟一个临时数组temp，拷贝传入数组arr的序列，对新数组temp进行排序。
* 在排序combineSort前后加入计时器start和end，作差可得到排序运行时间，并将每次的运行时间添加到数组runTime中。
* 数组minimal的设计：容量为10的容器，用来存储运较短运行时间对应的k值，可以对指针取%来重复利用空间。
* 遍历数组runTime，并用指针p索引数组minimal。当runTime[i]小于minimal当前位置存储的k值对应的运行时间时，更改minimal[p%10]为i+1(也就是runTime[i]对应的k)。这样能保证让运行时间最短的k一定在数组minimal里，同时其他9个数也是可以让运行时间接近最短的k。
* 
  * 若minimal中10个k的极差不大于15，则说明这个范围内的k都可以使combineSort效率达到较高水平。因此选取10个k的中位数作为目标k并返回。
  * 若极差大于15，则重新进行上述过程，直到minimal中10个k的极差不大于15为止。
* 我认为我的设计的合理性在于找到了“一簇”相近的、能使算法效率提高的k，相比起只找出一个k就返回，这样能一定程度避免偶然性。同时可能存在的问题是万一能使运行时间最短的k过于分散，找不到这样“一簇”k，这就会使selectK()陷入死循环——死循环是我们不想看到的，于是我把循环上限设为10次。若10次平行实验都没有找到一个合适的k，则返回0。但是在我的测试中没有遇到过这种情况。
* 附运行效果截图。经过多次测试，最终返回的k大概率分布在[30,70]，可见理论值和实验值有较高的重合度。
![avatar](1.3.png)
